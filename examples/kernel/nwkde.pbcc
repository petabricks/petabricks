#ifndef NWKDE_PBCC
#define NWKDE_PBCC

#include "nwkde.h"
#include "nwkdeGenerators.pbcc"
#include "nwkdeMetric.pbcc"
#include "utils.pbcc"

%{

/* wrap relative difference into [-180,180]
 * do most of the arithmetic in integers for speed
 * P360 and M360 indicate "plus 360" and "minus 360" */
inline double wrapWindDirDiff(double diff)
{
    /* add 360 *before* cast to round towards -INF instead of towards 0 */
    int diffIntP360 = (int) (diff + 360);

    /* add 180 to ensure modulo result is positive */
    int diffIntWrapP360 = ((diffIntP360 + 180) % 360) + 180;

    return diff + (diffIntWrapP360 - diffIntP360);
}

%}

transform NWKDECheckInputs
from TRAINDATA[m,n], TRAININDICES[l], TRAINVARINDEX[p], TRAINTIMEOFFSET[p],
     TESTDATA[m2,n2], TESTINDICES[q], TESTVARINDEX[p], TESTTIMEOFFSET[p],
     OUTPUTVARINDEX, OUTPUTTIMEOFFSET
to INPUTSCHECKED
{
    INPUTSCHECKED
    from (TRAININDICES trainIndices,
          TRAINVARINDEX trainVarIndex,
          TRAINTIMEOFFSET trainTimeOffset,
          TESTINDICES testIndices,
          TESTVARINDEX testVarIndex,
          TESTTIMEOFFSET testTimeOffset,
          OUTPUTVARINDEX outputVarIndex,
          OUTPUTTIMEOFFSET outputTimeOffset)
    {
        double min, max, min2, max2;

        findMinAndMax(&min, &max, trainVarIndex);
        fprintf(stderr, "trainVarIndex range: (%g, %g)\n", min, max);
        if (min < 0 || max > m) {
            fprintf(stderr, "trainVarIndex out of bounds: (%d, %d)\n", 0, m);
            PetabricksRuntime::abort();
        }

        fprintf(stderr, "outputVarIndex: %g\n", outputVarIndex);
        if (outputVarIndex < 0 || outputVarIndex > m) {
            fprintf(stderr, "outputVarIndex out of bounds: (%d, %d)\n", 0, m);
            PetabricksRuntime::abort();
        }

        findMinAndMax(&min, &max, testVarIndex);
        fprintf(stderr, "testVarIndex range: (%g, %g)\n", min, max);
        if (min < 0 || max > m2) {
            fprintf(stderr, "testVarIndex out of bounds: (%d, %d)\n", 0, m2);
            PetabricksRuntime::abort();
        }

        findMinAndMax(&min, &max, trainIndices);
        findMinAndMax(&min2, &max2, trainTimeOffset);
        fprintf(stderr, "trainIndices + trainTimeOffset range: (%g, %g)\n",
               min + min2, max + max2);
        if (min + min2 < 0 || max + max2 > n) {
            fprintf(stderr, "trainIndices + trainTimeOffset out of bounds: (%d, %d)\n",
                   0, n);
            PetabricksRuntime::abort();
        }

        fprintf(stderr, "trainIndices + outputTimeOffset range: (%g, %g)\n",
               min + outputTimeOffset, max + outputTimeOffset);
        if (min + outputTimeOffset < 0 || max + outputTimeOffset > n) {
            fprintf(stderr, "trainIndices + outputTimeOffset out of bounds: (%d, %d)\n",
                   0, n);
            PetabricksRuntime::abort();
        }

        findMinAndMax(&min, &max, testIndices);
        findMinAndMax(&min2, &max2, testTimeOffset);
        fprintf(stderr, "testIndices + testTimeOffset range: (%g, %g)\n",
               min + min2, max + max2);
        if (min + min2 < 0 || max + max2 > n2) {
            fprintf(stderr, "testIndices + testTimeOffset out of bounds: (%d, %d)\n",
                   0, n2);
            PetabricksRuntime::abort();
        }
    }
}

/*  TRAINDATA - block of data: n time slices, m variables per time slice
    TRAININDICES - l time indices into TRAINDATA to use for training

    TESTDATA - block of data: n2 time slices, m2 variables per time slice
    TESTINDICES - q indices into TESTDATA to evaluate the regression

    WRAPFLAGS - indicates whether TRAINDATA column corresponds to a wind
                direction \in [0, 360]
    KERNELWIDTHS - width of the kernel function to use for a data column

    For each time index in TRAININDICES or TESTINDICES, we associate
    a p-dim vector of predictors for use during regression.  The
    TRAINVARINDEX array contains the column index (into TRAINDATA) of
    the variable to use for each predictor.  The TRAINTIMEOFFSET array
    contains the time offset relative to the current time index.  In this way,
    we can build predictor vectors that contain overlapping data for
    different time indices.  Similarly, TESTVARINDEX and TESTTIMEOFFSET
    specify the predictor vector to use when computing the regression output.

    OUTPUTVARINDEX - which variable in TRAINDATA for output
    OUTPUTTIMEOFFSET - time offset from trainIndex in TRAINDATA for output
    TRAINMASKWIDTH - width of training mask.  This tells the transform to
                     omit training indices less than TRAINMASKWIDTH
                     indices of the test index when computing the regression.
                     Note: to be used when TESTDATA is equal to TRAINDATA.
                     May set to 0 (no mask effect) if TESTDATA is separate
                     from TRAINDATA.

    SQDIFFS - squared differences for each predictor for each train-test
              point pair
    WEIGHTS - weights computed with Gaussian kernel function for each
              train-test point pair
    PARTIALS - weighted output partial sums
*/

transform NWKDEBase
from TRAINDATA[m,n], WRAPFLAGS[m], KERNELWIDTHS[m],
     TRAININDICES[l], TRAINVARINDEX[p], TRAINTIMEOFFSET[p],
     TESTDATA[m2,n2],
     TESTINDICES[q], TESTVARINDEX[p], TESTTIMEOFFSET[p],
     OUTPUTVARINDEX, OUTPUTTIMEOFFSET,
     TRAINMASKWIDTH
to RESULT[q]
through SQDIFFS[p,l,q], WEIGHTS[l,q], PARTIALS[l,q]
{

    /* METHOD 1: compute PARTIALS by exposing the most fine-grained
       parallelism.  this method may be less cache-efficient depending on
       execution ordering. */

    to   (SQDIFFS.cell(i,j,k) sqDiff)
    from (TRAINDATA trainData,
          WRAPFLAGS wrapFlags,
          KERNELWIDTHS kernelWidths,
          TRAININDICES.cell(j) trainIndex,
          TRAINVARINDEX.cell(i) trainVarIndex,
          TRAINTIMEOFFSET.cell(i) trainTimeOffset,
          TESTDATA testData,
          TESTINDICES.cell(k) testIndex,
          TESTVARINDEX.cell(i) testVarIndex,
          TESTTIMEOFFSET.cell(i) testTimeOffset)
    {
        int wrapFlag = (int) wrapFlags.cell((int) trainVarIndex);
        double kernelWidth = kernelWidths.cell((int) trainVarIndex);

        int trainTimeIndex = (int) trainIndex + (int) trainTimeOffset;
        int  testTimeIndex = (int)  testIndex + (int)  testTimeOffset;

        double trainPoint = trainData.cell((int) trainVarIndex, trainTimeIndex);
        double  testPoint =  testData.cell((int)  testVarIndex,  testTimeIndex);

        double diff = trainPoint - testPoint;

        if (wrapFlag) {
            diff = wrapWindDirDiff(diff);
        }

        // normalize according to kernel width
        diff /= kernelWidth;

        // return squared difference
        sqDiff = diff * diff;
#ifdef DEBUG
        fprintf(stderr, "method 1:  sqdiff(%d, %d, %d) = %g\n", i, j, k, sqDiff);
#endif
    }

    to (WEIGHTS.cell(j,k) weight)
    from (SQDIFFS.region(0, j,   k,
                         p ,j+1, k+1) sqDiffs,
          TRAININDICES.cell(j) trainIndex,
          TESTINDICES.cell(k) testIndex,
          TRAINMASKWIDTH trainMaskWidth)
    {
        if (trainIndex <= testIndex - trainMaskWidth ||
            trainIndex >= testIndex + trainMaskWidth) {
            ReduceAdd(weight, sqDiffs.slice(2,0).slice(1,0));
            weight = exp(-((double) weight));
        } else {
            weight = 0;
        }
#ifdef DEBUG
        fprintf(stderr, "method 1:  weight(%d, %d) = %g\n", j, k, weight);
#endif
    }

    to (PARTIALS.cell(j,k) partial)
    from (TRAINDATA trainData,
          TRAININDICES.cell(j) trainIndex,
          OUTPUTVARINDEX outputVarIndex,
          OUTPUTTIMEOFFSET outputTimeOffset,
          WEIGHTS.cell(j,k) weight)
    {
        int timeIndex = (int) trainIndex + (int) outputTimeOffset;
        partial = trainData.cell((int) outputVarIndex, timeIndex);
        partial *= weight;
#ifdef DEBUG
        fprintf(stderr, "method 1: partial(%d, %d) = %g\n", j, k, partial);
#endif
    }

    /* METHOD 2: Compute weights and partials directly with one pass through the data */

    to   (PARTIALS.cell(j,k) partial,
          WEIGHTS.cell(j,k) weight)
    from (TRAINDATA trainData,
          WRAPFLAGS wrapFlags,
          KERNELWIDTHS kernelWidths,
          TRAININDICES.cell(j) trainIndex,
          TRAINVARINDEX trainVarIndex,
          TRAINTIMEOFFSET trainTimeOffset,
          TESTDATA testData,
          TESTINDICES.cell(k) testIndex,
          TESTVARINDEX testVarIndex,
          TESTTIMEOFFSET testTimeOffset,
          OUTPUTVARINDEX outputVarIndex,
          OUTPUTTIMEOFFSET outputTimeOffset,
          TRAINMASKWIDTH trainMaskWidth)
    {
        double sum = 0;

        if (trainIndex <= testIndex - trainMaskWidth ||
            trainIndex >= testIndex + trainMaskWidth) {
            for (int i = 0; i < trainVarIndex.count(); ++i) {

                int wrapFlag = (int) wrapFlags.cell((int) trainVarIndex.cell(i));
                double kernelWidth = kernelWidths.cell((int) trainVarIndex.cell(i));

                int trainTimeIndex = (int) trainIndex + (int) trainTimeOffset.cell(i);
                int  testTimeIndex = (int)  testIndex + (int)  testTimeOffset.cell(i);

                double trainPoint = trainData.cell((int) trainVarIndex.cell(i), trainTimeIndex);
                double  testPoint =  testData.cell((int)  testVarIndex.cell(i),  testTimeIndex);

                double diff = trainPoint - testPoint;

                if (wrapFlag) {
                    diff = wrapWindDirDiff(diff);
                }

                // normalize according to kernel width
                diff /= kernelWidth;

                // return squared difference
                sum += diff * diff;
            }
            weight = exp(-((double) sum));
        } else {
            weight = 0;
        }

        int outputTimeIndex = (int) trainIndex + (int) outputTimeOffset;
        partial = weight * trainData.cell((int) outputVarIndex, outputTimeIndex);
#ifdef DEBUG
        fprintf(stderr, "method 2:  weight(%d, %d) = %g\n", j, k, weight);
        fprintf(stderr, "method 2: partial(%d, %d) = %g\n", j, k, partial);
#endif
    }

    /* METHOD 3: Compute results directly with one pass through the data */

    to   (RESULT.cell(k) result)
    from (TRAINDATA trainData,
          WRAPFLAGS wrapFlags,
          KERNELWIDTHS kernelWidths,
          TRAININDICES trainIndices,
          TRAINVARINDEX trainVarIndex,
          TRAINTIMEOFFSET trainTimeOffset,
          TESTDATA testData,
          TESTINDICES.cell(k) testIndex,
          TESTVARINDEX testVarIndex,
          TESTTIMEOFFSET testTimeOffset,
          OUTPUTVARINDEX outputVarIndex,
          OUTPUTTIMEOFFSET outputTimeOffset,
          TRAINMASKWIDTH trainMaskWidth)
    {
        double totalPartial = 0, totalWeight = 0, weight;

        // loop over training points
        for (int j = 0; j < trainIndices.count(); ++j) {

            int trainIndex = (int) trainIndices.cell(j);

            // TODO: get rid of branch inside loop by splitting outer for
            // loop into two loops.  Need to modularize loop interior for code
            // clarity.
            if (trainIndex <= testIndex - trainMaskWidth ||
                trainIndex >= testIndex + trainMaskWidth) {
                // loop over predictor variables
                double sum = 0;
                for (int i = 0; i < trainVarIndex.count(); ++i) {

                    int wrapFlag = (int) wrapFlags.cell((int) trainVarIndex.cell(i));
                    double kernelWidth = kernelWidths.cell((int) trainVarIndex.cell(i));

                    int trainTimeIndex = (int) trainIndex + (int) trainTimeOffset.cell(i);
                    int  testTimeIndex = (int)  testIndex + (int)  testTimeOffset.cell(i);

                    double trainPoint = trainData.cell((int) trainVarIndex.cell(i), trainTimeIndex);
                    double  testPoint =  testData.cell((int)  testVarIndex.cell(i),  testTimeIndex);

                    double diff = trainPoint - testPoint;

                    if (wrapFlag) {
                        diff = wrapWindDirDiff(diff);
                    }

                    // normalize according to kernel width
                    diff /= kernelWidth;

                    // return squared difference
                    sum += diff * diff;
                }
                weight = exp(-((double) sum));
            } else {
                weight = 0;
            }

            int outputTimeIndex = (int) trainIndex + (int) outputTimeOffset;
            double partial = weight * trainData.cell((int) outputVarIndex, outputTimeIndex);

#ifdef DEBUG
            fprintf(stderr, "method 3:  weight(%d, %d) = %g\n", j, k, weight);
            fprintf(stderr, "method 3: partial(%d, %d) = %g\n", j, k, partial);
#endif
            totalWeight += weight;
            totalPartial += partial;
        }

        result = totalPartial / totalWeight;
#ifdef DEBUG
        fprintf(stderr, "Output %d = %g\n", k, result);
#endif // DEBUG
    }

    /* Once we have the PARTIALS and WEIGHTS, we can compute RESULT */

    to (RESULT.cell(k) result)
    from (PARTIALS.row(k) partials,
          WEIGHTS.row(k) weights)
    {
        double totalWeight;
        ReduceAdd(result, partials);
        ReduceAdd(totalWeight, weights);
        result /= totalWeight;
#ifdef DEBUG
        fprintf(stderr, "Output %d = %g\n", k, result);
#endif // DEBUG
    }
}

transform NWKDERecursive
from TRAINDATA[m,n], WRAPFLAGS[m], KERNELWIDTHS[m],
     TRAININDICES[l], TRAINVARINDEX[p], TRAINTIMEOFFSET[p],
     TESTDATA[m2,n2],
     TESTINDICES[q], TESTVARINDEX[p], TESTTIMEOFFSET[p],
     OUTPUTVARINDEX, OUTPUTTIMEOFFSET, TRAINMASKWIDTH
to RESULT[q]
{
    to   (RESULT           result)
    from (TRAINDATA        trainData,
          WRAPFLAGS        wrapFlags,
          KERNELWIDTHS     kernelWidths,
          TRAININDICES     trainIndices,
          TRAINVARINDEX    trainVarIndex,
          TRAINTIMEOFFSET  trainTimeOffset,
          TESTDATA         testData,
          TESTINDICES      testIndices,
          TESTVARINDEX     testVarIndex,
          TESTTIMEOFFSET   testTimeOffset,
          OUTPUTVARINDEX   outputVarIndex,
          OUTPUTTIMEOFFSET outputTimeOffset,
          TRAINMASKWIDTH   trainMaskWidth)
    {
        NWKDEBase(result, trainData, wrapFlags, kernelWidths,
                  trainIndices, trainVarIndex, trainTimeOffset,
                  testData, testIndices,
                  testVarIndex, testTimeOffset,
                  outputVarIndex, outputTimeOffset, trainMaskWidth);
    }

    to   (RESULT           result)
    from (TRAINDATA        trainData,
          WRAPFLAGS        wrapFlags,
          KERNELWIDTHS     kernelWidths,
          TRAININDICES     trainIndices,
          TRAINVARINDEX    trainVarIndex,
          TRAINTIMEOFFSET  trainTimeOffset,
          TESTDATA         testData,
          TESTINDICES      testIndices,
          TESTVARINDEX     testVarIndex,
          TESTTIMEOFFSET   testTimeOffset,
          OUTPUTVARINDEX   outputVarIndex,
          OUTPUTTIMEOFFSET outputTimeOffset,
          TRAINMASKWIDTH   trainMaskWidth)
    {
        int mid = q / 2;

        if (mid > 0) {
            NWKDERecursive(result.region(0, mid),
                           trainData, wrapFlags, kernelWidths,
                           trainIndices, trainVarIndex, trainTimeOffset,
                           testData, testIndices.region(0, mid),
                           testVarIndex, testTimeOffset,
                           outputVarIndex, outputTimeOffset, trainMaskWidth);
        }

        if (mid < q) {
            NWKDERecursive(result.region(mid, q),
                           trainData, wrapFlags, kernelWidths,
                           trainIndices, trainVarIndex, trainTimeOffset,
                           testData, testIndices.region(mid, q),
                           testVarIndex, testTimeOffset,
                           outputVarIndex, outputTimeOffset, trainMaskWidth);
        }

    }
}

transform NWKDE
// PPBUG: the following ifdef shouldn't be necessary since the parameter
//   sizes are controlled in nwkde.h.  However, the variable dimensions
//   controlled by the --n parameter appear to be determined before the
//   preprocessor substitutions occur, causing size mismatches with the
//   NWKDE generators.
#ifdef WORKAROUND
from TRAINDATA[4,8750], WRAPFLAGS[4], KERNELWIDTHS[4],
     TRAININDICES[l], TRAINVARINDEX[8], TRAINTIMEOFFSET[8],
     TESTDATA[4,8750],
     TESTINDICES[q], TESTVARINDEX[8], TESTTIMEOFFSET[8],
     OUTPUTVARINDEX, OUTPUTTIMEOFFSET, TRAINMASKWIDTH
to RESULT[q]
#else
from TRAINDATA[M,N], WRAPFLAGS[M], KERNELWIDTHS[M],
     TRAININDICES[L], TRAINVARINDEX[P], TRAINTIMEOFFSET[P],
     TESTDATA[M2,N2],
     TESTINDICES[Q], TESTVARINDEX[P], TESTTIMEOFFSET[P],
     OUTPUTVARINDEX, OUTPUTTIMEOFFSET, TRAINMASKWIDTH
to RESULT[Q]
#endif
through INPUTSCHECKED
generator NWKDEGenerator3
accuracy_metric NWKDEMetric2
{
    to (RESULT result)
    from (TRAINDATA        trainData,
          WRAPFLAGS        wrapFlags,
          KERNELWIDTHS     kernelWidths,
          TRAININDICES     trainIndices,
          TRAINVARINDEX    trainVarIndex,
          TRAINTIMEOFFSET  trainTimeOffset,
          TESTDATA         testData,
          TESTINDICES      testIndices,
          TESTVARINDEX     testVarIndex,
          TESTTIMEOFFSET   testTimeOffset,
          OUTPUTVARINDEX   outputVarIndex,
          OUTPUTTIMEOFFSET outputTimeOffset,
          TRAINMASKWIDTH   trainMaskWidth)
    {
#ifdef DEBUG
        double ret;
        NWKDECheckInputs(ret, trainData, trainIndices,
                         trainVarIndex, trainTimeOffset,
                         testData, testIndices,
                         testVarIndex, testTimeOffset,
                         outputVarIndex, outputTimeOffset);
#endif
        NWKDERecursive(result, trainData, wrapFlags, kernelWidths,
                       trainIndices, trainVarIndex, trainTimeOffset,
                       testData, testIndices,
                       testVarIndex, testTimeOffset,
                       outputVarIndex, outputTimeOffset, trainMaskWidth);
    }
}

#endif // NWKDE_PBCC
